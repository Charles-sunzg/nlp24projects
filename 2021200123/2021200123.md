# 项目报告：基于GPT2中文大模型的古诗词生成模型
孙志钢 2021200123
## 1. 研究背景和研究目标
### 1.1 研究背景
古诗词作为中国传统文化的瑰宝，具有深厚的历史背景和广泛的文化影响力。它们不仅是文学艺术的表现形式，也承载了丰富的哲学思想、历史故事、情感表达等内容。

随着人工智能和自然语言处理（NLP）技术的飞速发展，深度学习模型，特别是基于神经网络的生成模型，已经在多个领域取得了突破。近年来，GPT系列模型、BERT、Transformer等技术的出现使得语言生成任务，尤其是文学创作，进入了新的阶段。

尽管现代技术在诗词创作方面已取得一定进展，但由于古诗词具有独特的韵律、对仗、意境等要求，古诗词的自动生成依然面临诸多挑战。许多早期的模型未能很好地解决语言流畅性、文化底蕴与创意之间的平衡问题。因此，如何利用深度学习技术生成具有较高文学价值的古诗词，成为了一个重要的研究方向。

### 1.2 研究目的
目前的自动古诗词生成模型面临的问题包括语法结构不准确、韵律不和谐、情感表达不到位等。研究的目的之一是通过改进模型架构，优化训练数据，增强模型对古诗词特征的学习能力，提高生成诗词的质量与准确性，使其更具文学性与艺术性。

## 2. 数据准备
本项目采用中华诗词数据库，数据库链接：[诗词数据库](https://github.com/chinese-poetry/chinese-poetry)

此数据库是最全的中华古典文集数据库，包含 5.5 万首唐诗、26 万首宋诗、2.1 万首宋词和其他古典文集。诗人包括唐宋两朝近 1.4 万古诗人，和两宋时期 1.5 千古词人。数据来源于互联网。

本项目提取其中的5.5 万首唐诗、26 万首宋诗、2.1 万首宋词作为训练集进行训练，利用数据库进行基本操作后转化为csv。详细路径见[数据](.\src\data_path.md)

## 3. LSTM模型尝试
本次首先采用LSTM模型进行初步的生成模型训练

### 3.1 数据处理
由于数据库主要为繁体字，首先调用 



